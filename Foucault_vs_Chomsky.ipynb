{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tally\\.virtualenvs\\Repositories-J01Zxu1S\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "aLdX4J785gXQ",
    "outputId": "1edf7396-9e94-42e1-fa6b-04832907fa2b"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from os import mkdir\n",
    "import requests\n",
    "#Dicitionary used to access full book text in HTML format\n",
    "urls = {'foucault_madness_and_civ':'https://archive.org/stream/Michel_Foucault_Madness_And_Civilization/Michel%20Foucault%2C%20Richard%20Howard%20%28transl.%29%20-%20Madness%20and%20Civilization_%20A%20History%20of%20Insanity%20in%20the%20Age%20of%20Reason%20%282013%2C%20Vintage%29_djvu.txt',\n",
    "        'foucault_history_of_sexuality':'https://archive.org/stream/TheHistoryOfSexualityVol13/The-History-Of-Sexuality-Vol-1-3_djvu.txt',\n",
    "        'chomsky_american_power': 'https://archive.org/stream/AmericanPowerAndTheNewMandarins_201805/American%20Power%20And%20The%20New%20Mandarins_djvu.txt',\n",
    "        'chomsky_manufacturing_consent': 'https://archive.org/stream/revhosatx14/%5BEdward_S._Herman%2C_Noam_Chomsky%5D_Manufacturing_Con%28b-ok.org%29_djvu.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_books(title, link):\n",
    "    '''Create directories for book from title and link'''\n",
    "    #Access HTML webpage on Internet Archive\n",
    "    r = requests.get(link)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data)\n",
    "    #Full text is in <pre> part of HTML doc\n",
    "    book = soup.pre.string\n",
    "    #Write book as text file, save file\n",
    "    with open(f'./data/{title}.txt', 'w', encoding='utf-8') as book_file:\n",
    "        book_file.write(book)\n",
    "        #Make a folder for each book\n",
    "        mkdir(f'./data/{title}_extracts')\n",
    "def split_book(title, n_lines=5):\n",
    "    '''Split a text file based on a number of lines, book title'''\n",
    "    #Find file path based on title\n",
    "    filepath = f'./data/{title}.txt'\n",
    "    #Extract directory and filename from file path\n",
    "    path, filename = os.path.split(filepath)\n",
    "    #Change path to book's directory\n",
    "    path += f'/{title}_extracts'\n",
    "    # filename.split('.') would not work for filenames with more than one .\n",
    "    basename, ext = os.path.splitext(filename)\n",
    "    #open input file\n",
    "    with open(filepath, 'r', encoding='utf-8') as book_file:\n",
    "        try:\n",
    "            #open the first output(extract) file\n",
    "            extract_file = open(os.path.join(path, '{}_{}{}'.format(basename, 0, ext)), 'w', encoding='utf-8')\n",
    "            #Loop over all lines of input file, number them\n",
    "            for i, line in enumerate(book_file):\n",
    "                #Close extract file and open a new one\n",
    "                #When the line number % desired n_lines is 0\n",
    "                if i % n_lines == 0:\n",
    "                    extract_file.close()\n",
    "                    #Open the next output file to write the next extract\n",
    "                    extract_file = open(os.path.join(path, '{}_{}{}'.format(basename, i/100, ext)), 'w', encoding='utf-8')\n",
    "                #write the line to extract file\n",
    "                extract_file.write(line)\n",
    "        finally:\n",
    "            #close last output file\n",
    "            extract_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./data'):  \n",
    "    os.mkdir('./data')\n",
    "    for title, link in urls.items():\n",
    "        file_books(title, link)\n",
    "        split_book(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    '''Tokenizer with lemmatizer'''\n",
    "    return [token.lemma_ for token in nlp(doc) if (token.is_stop == False) &\n",
    "            (token.is_punct == False) & (token.is_space == False) &\n",
    "            (token.is_upper == False) & (token.pos_ != 'PROPN')]\n",
    "def gather_data(path_to_data):\n",
    "    path = f'./data/{path_to_data}'\n",
    "    data = {'extracts': [], 'author': []}\n",
    "    #For file at the given path\n",
    "    for file in os.listdir(path):\n",
    "        #If the directory is not a folder\n",
    "        if os.path.isdir(file) == False:\n",
    "            #If the file type is .txt\n",
    "            if file[-3:] == 'txt':\n",
    "                #Open each text file at the path provided\n",
    "                with open(os.path.join(path, file), encoding='utf-8') as t:\n",
    "                    #Read and strip new line signal\n",
    "                    text = t.read().replace('\\n', ' ')\n",
    "                    data['extracts'].append(str(text))\n",
    "                    data['author'].append(path_to_data.split('_')[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3N0RmPm6dHm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leave', 'life', 'believe']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('If you should ever leave me, Jack your life would still go on believe me')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anjsdCcSlbTe"
   },
   "outputs": [],
   "source": [
    "extracts_dirs = [folder for folder in os.listdir('./data') if (os.path.isdir(f'./data/{folder}') == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17839, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracts</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:| r?|| f • &gt;0* rl; 1=/!= If j</td>\n",
       "      <td>chomsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'   a?KJii5K;jp«a;KWSg;«K</td>\n",
       "      <td>chomsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ffc =£; £r fffjil rI^|l£=£|/F~*f HScIf£|||    ...</td>\n",
       "      <td>chomsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ilfiiiliilililllliliilliiliilil:   5ffi||||^p|...</td>\n",
       "      <td>chomsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.   liii/sf;</td>\n",
       "      <td>chomsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            extracts   author\n",
       "0                :| r?|| f • >0* rl; 1=/!= If j       chomsky\n",
       "1                       '   a?KJii5K;jp«a;KWSg;«K     chomsky\n",
       "2  Ffc =£; £r fffjil rI^|l£=£|/F~*f HScIf£|||    ...  chomsky\n",
       "3  ilfiiiliilililllliliilliiliilil:   5ffi||||^p|...  chomsky\n",
       "4                                    .   liii/sf;     chomsky"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame({'extracts': [], 'author': []})\n",
    "for directory in extracts_dirs:\n",
    "    extracts = gather_data(directory)\n",
    "    df = pd.DataFrame(extracts, columns = extracts.keys())\n",
    "    df_final = pd.concat([df_final, df], axis=0)\n",
    "#     print(extracts['author'])\n",
    "#     print(directory)\n",
    "print(df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_final['extracts']\n",
    "y = df_final['author']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search w/ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "counter = TfidfVectorizer(\n",
    "#     max_df = .97,\n",
    "#                           min_df = 5,\n",
    "#                           stop_words='english',\n",
    "# #                           ngram_range= (1,3),\n",
    "                          tokenizer=tokenize)\n",
    "\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('counter', counter),\n",
    "                     ('rf', rf)])\n",
    "parameters = {\n",
    "    'counter__max_df': [i/100 for i in range(75, 100)],\n",
    "    'counter__min_df': range(0, 10),\n",
    "    'counter__ngram_range': [(1,2), (1,1), (1, 3), (2,3)],\n",
    "    'rf__max_depth': range(5,20),\n",
    "    'rf__min_samples_split': range(2, 10),\n",
    "    'rf__min_samples_leaf': range(1,50)\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipeline, parameters, cv=3, n_iter=10, n_jobs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] rf__min_samples_split=8, rf__min_samples_leaf=27, rf__max_depth=17, counter__ngram_range=(1, 2), counter__min_df=2, counter__max_df=0.88 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\tally\\.virtualenvs\\Repositories-J01Zxu1S\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__min_samples_split=8, rf__min_samples_leaf=27, rf__max_depth=17, counter__ngram_range=(1, 2), counter__min_df=2, counter__max_df=0.88, total= 3.5min\n",
      "[CV] rf__min_samples_split=8, rf__min_samples_leaf=27, rf__max_depth=17, counter__ngram_range=(1, 2), counter__min_df=2, counter__max_df=0.88 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.9min remaining:    0.0s\n",
      "C:\\Users\\tally\\.virtualenvs\\Repositories-J01Zxu1S\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__min_samples_split=8, rf__min_samples_leaf=27, rf__max_depth=17, counter__ngram_range=(1, 2), counter__min_df=2, counter__max_df=0.88, total= 3.1min\n",
      "[CV] rf__min_samples_split=8, rf__min_samples_leaf=27, rf__max_depth=17, counter__ngram_range=(1, 2), counter__min_df=2, counter__max_df=0.88 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tally\\.virtualenvs\\Repositories-J01Zxu1S\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__min_samples_split=8, rf__min_samples_leaf=27, rf__max_depth=17, counter__ngram_range=(1, 2), counter__min_df=2, counter__max_df=0.88, total= 3.6min\n",
      "[CV] rf__min_samples_split=8, rf__min_samples_leaf=11, rf__max_depth=7, counter__ngram_range=(1, 3), counter__min_df=3, counter__max_df=0.98 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tally\\.virtualenvs\\Repositories-J01Zxu1S\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "best = rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_estimator_.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = best.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_estimator_.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_estimator_.predict_proba(['chomsky'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "best.best_estimator_.predict([\"\"\"was therefore suspect from \n",
    "the start, and an “alternative model 55 of inducement-pressure coaching \n",
    "was plausible and relevant, from the Agca 5 s first implication of Bulgari¬ \n",
    "ans. This model became more cogent over time as Agca retracted \n",
    "strategic claims, and as no confirming evidence of a Bulgarian Connec¬ \n",
    "tion was produced. By the same token, the SHK model, implausible \n",
    "from the beginning, became even less tenable. \n",
    "\n",
    "\n",
    "4.4. THE MASS MEDIA’S \n",
    "UNCRITICAL ACCEPTANCE OF \n",
    "THE BULGARIAN CONNECTION \n",
    "\n",
    "\n",
    "Despite the implausibility of the SHK claim that Agca had been hired \n",
    "by the Bulgarians and the KGB to shoot the pope, and although it was \n",
    "\n",
    "\n",
    "\n",
    "THE KGB-BULG ARIAN PLOT TO KILL THE POPE I55 \n",
    "\n",
    "\n",
    "sustained by argument that amounted to sheer humbuggery, the Bul¬ \n",
    "garian Connection met the standard of utility. In this case, therefore, \n",
    "as a propaganda model would anticipate, the U.S. mass media accepted \n",
    "the SHK model as valid, ignored the alternative model, and par¬ \n",
    "ticipated in a classic propaganda campaign that got the message of \n",
    "Bulgarian-Soviet guilt over to the public. Some members of the mass \n",
    "media helped originate the claim of a Bulgarian Connection, while \n",
    "others participated only in disseminating the SHK line (and excluding \n",
    "alternative views and inconvenient information). \n",
    "\n",
    "The campaign began with Sterling’s Reader’s Digest article of Sep¬ \n",
    "tember 1982, which was closely followed by the NBC-TV program of \n",
    "September 21, 1982, The outreach of these two statements asserting a \n",
    "Bulgarian Connection was great, and they were widely reported upon \n",
    "in the rest of the media in the form of a summary of their claims, with \n",
    "virtually no questions raised about their validity. With Agca’s Novem¬ \n",
    "ber 1982 naming of Bulgarians, the mass media began to report the \n",
    "Bulgarian Connection intensively. This reporting was carried out ex¬ \n",
    "clusively within the frame of the SHK model, and for most of the mass \n",
    "media no serious departures from this model occurred through the \n",
    "conclusion of the Rome trial in March 1986. 24 \n",
    "\n",
    "Agca’s naming of the Bulgarians was the key fact that generated news \n",
    "coverage, providing the basis for reiterated details about the Bulgarians, \n",
    "explanations of the Bulgarian (and Soviet) motive, and speculation \n",
    "about the political implications of the charges, if confirmed. A major \n",
    "characteristic of these news reports was their sheer superficiality, with \n",
    "the charges never seriously examined but merely regurgitated and \n",
    "elaborated with odd facts and opinion, and with no departures from the \n",
    "SHK frame (and no hints of the possible relevance of an alternative \n",
    "frame). The charges constituted a form of vindication of the SHK \n",
    "model if taken at face value and presented superficially—i.e., if the \n",
    "media presentations never considered political convenience, prison \n",
    "conditions, possible deals, plausible deniability, etc* And this proce¬ \n",
    "dure—a reiteration of Agca claims, supplemented by extremely super¬ \n",
    "ficial pro-plot speculation—was the principal modality by which the \n",
    "mass media accepted and pushed the propaganda line, \n",
    "\n",
    "Newsweek provides a prototype of news coverage within the SHK \n",
    "framework in its article of January 3,1983, “The Plot to Kill Pope John \n",
    "Paul II.” The Bulgarian-Soviet motive as portrayed by SHK is reite¬ \n",
    "rated through quotes from congenial sources—“a precautionary and \n",
    "alternative solution to the invasion of Poland”—while nobody is quoted \n",
    "discussing costs and benefits, the nature of the Soviet leadership, or \n",
    "Western benefits from Agca’s confession. 25 In fact, Newsweek suggests \n",
    "\n",
    "\n",
    "\n",
    "156 MANUFACTURING CONSENT \n",
    "\n",
    "\"\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Foucault vs Chomsky.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "python-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
